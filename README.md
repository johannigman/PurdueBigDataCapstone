# MGMT 590 Big Data Capstone
## Determining the Effacacy of a Deep Learning Model Trained on Historical SPAM Data on Modern Emails

Although communication technologies have evolved so much in the past two decades, email has remained one of the most relevant tools in personal and business communications. The average email recipient would receive hundreds of emails monthly. Not all those emails are wanted.  Unwanted emails, most often classified as spam emails, are becoming an issue for every individual or business. They can be a gateway for cybercriminals leading to data breaches. They can lead to great inconvenience for individuals when their frequency hinders important emails. Lately spam emails have been linked to data security, and companies have been working more diligently in recognizing them. Spam emails can be costly. Per an analysis conducted in 2020, in academia alone, the cost of spam emails can amount to 2.6 billion US dollars per year (Texeira da Silva et al). Another source like the website [Cybersecuritydive.com](https://www.cybersecuritydive.com/news/phishing-cost-enterprise/605110/#:~:text=The%20financial%20impact%20of%20phishing%20attacks,according%20to%20a%20study%20from%20the&text=The%20financial%20impact%20of,a%20study%20from%20the&text=impact%20of%20phishing%20attacks,according%20to%20a%20study) report an average cost of 14.8 million US dollars per year for US companies in 2021. All those make spam detection a subject of interest for individuals, businesses, governments, and academics. 

Recognizing spam email has caught the attention of many academic researchers. Several studies have attempted to come up with the best models for spam detection. In general, as reported by Idris et al (2014), two main approaches have been used: a knowledge engineering approach and a machine learning approach. Regardless of the approach, the techniques for spam detection can be based on checking the address of the incoming email, using key word to determine if an email is spam or not, classifying email based on their contexts, or on the word frequency of one or more words in a given message (Kaya et al., 2016). 

For this project, we will be using a machine learning approach and content-based techniques for spam detection. Due to the complexity of applying natural language processing and building a deep learning model that can handle spam detection we have chosen to utilize a pre-existing deep learning model detailed in this [article](https://towardsdatascience.com/spam-detection-in-emails-de0398ea3b48) by Ramya Vidiyala.  The original code for this model was included in [this Jupyter notebook in Github](https://github.com/RamyaVidiyala/SpamDetectionInEmails/blob/master/SpamDetection.ipynb).  The data used to train the model is from [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) and is dated back to 2012. Knowing how email languages have evolved we would like to determine if the model is still effective on more modern emails. We will be incorporating the referenced deep learning model into a data pipeline in Google Cloud Platform that can read mails from a mail API, classify them as spam or not, and stream them to a table in Google Big Query for further analysis.  We will analyze the resulting dataset to determine the effectiveness of this model on modern email communications and determine further ways in which we could improve the performance of the model.

## Documentation
- The primary repository contains the python code that can be deployed as a Google Cloud Function referencing the getmail function in main.py.  You will need to supply credentials to connect to Gmail and Google Cloud Storage in order for it to pickup emails and send them to Google Cloud Storage to trigger the streaming pipeline to pick them up.  When deploying the Cloud Function you will need a container that has at least 1GB of memory or the container will run out of memory.  The trained model is saved to spam.keras.

- The schemas folder contains schemas for Google Big Query to create the table needed to land the email data into.

- The training_model folder contains the above referenced machine learning model code, spam.csv, which is the training dataset that was used to train our model, and word_index.txt which is the word index that was generated from model training.  This dictionary has to be reutilized by the model in order to ensure that the tokens are processed correctly by our saved model (spam.keras)

- We used standard Google Dataflow templates to create streaming jobs that streamed the emails received in GCS to a pub/sub topic and create a subscription to stream the data in the pub/sub topic to Google Big Query.
